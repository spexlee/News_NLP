{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜별 워드 클라우드로 가장 빈도수 높은 단어 도출 (title)\n",
    "- 이예빈\n",
    "- 참고: 불용어 사전 (https://www.ranks.nl/stopwords/korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from konlpy.tag import Okt\n",
    "import matplotlib.pyplot as plt\n",
    "import MeCab\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not(os.path.isdir('../../data/press')):\n",
    "        os.makedirs(os.path.join('../../data/press'))\n",
    "                    \n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV_List로 만드는 함수\n",
    "def csv2list(filename):\n",
    "    lists = []\n",
    "    file = open(filename,'r',encoding='utf-8')\n",
    "    while True:\n",
    "        line = file.readline().rstrip('\\n')\n",
    "        if line:\n",
    "            lists.append(line)\n",
    "        else:\n",
    "            break\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = csv2list('../../data/stop_words/stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 뉴스 제목에서 기호 제거 & 명사 추출 \n",
    "\n",
    "def title_preprocessing(title, okt):\n",
    "    title_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', ' ', title)\n",
    "    word_title = okt.nouns(title_text) \n",
    "    word_title = [word for word in word_title if not word in stop_words] # 불용어 제거\n",
    "    \n",
    "    return word_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전처리된 데이터프레임 by_day를 반환합니다. \n",
    "## file: csv파일이 들어있는 경로를 지정해주세요. (+ 파일까지 포함되도록!)\n",
    "\n",
    "def all_preprocessing(file):\n",
    "    df_file = pd.read_csv(file, encoding='utf-8')\n",
    "    \n",
    "    title = df_file['title']\n",
    "    date_ = df_file['date']\n",
    "    df = pd.DataFrame({'title':title, 'date':date_})\n",
    "    \n",
    "    okt = Okt()\n",
    "    clean_text = []\n",
    "    for title in df_file['title']:\n",
    "        if type(title)==str:\n",
    "            clean_text.append(title_preprocessing(title, okt))\n",
    "        else:\n",
    "            clean_text.append([])\n",
    "    df['title'] = clean_text\n",
    "    \n",
    "    # date 컬럼 -> datetime으로 설정 \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    by_day = df.groupby(df['date']).sum()\n",
    "\n",
    "    # 딕셔너리 풀기\n",
    "    title_text = []\n",
    "    for i in range(len(by_day['title'])):\n",
    "        title_text.append(', '.join(by_day['title'][i]))\n",
    "\n",
    "    by_day['title'] = title_text\n",
    "    by_day.to_csv('../../data/press/donga _title.csv', encoding='utf-8')\n",
    "    \n",
    "    return by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>공무원, 증, 밥값, 결제, 혁신, 준, 정부, 나은, 준비, 민주, 열망, 시대,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>김정은, 전략, 무기, 모라토리엄, 파기, 위협, 전문가, 공직, 배급, 스타트업,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>처지, 끝장, 생존, 게임, 구도, 오른, 총선, 전쟁, 패트, 몸싸움, 여야, 총...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>트럼프, 중동, 화약고, 기업, 법, 시행, 땐, 툭하면, 공장, 이낙연, 황교안,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>법무부, 검사, 출신, 검찰, 국장, 기용, 검토, 이란, 시설, 타깃, 트럼프, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-27</th>\n",
       "      <td>의협, 파업, 강행, 정부, 면허, 취소, 압박, 기상청, 차량, 전복, 위험, 서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-28</th>\n",
       "      <td>단독, 교수, 진도, 파업, 동참, 서울대, 병원, 내과, 서나, 감염, 대통령, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-29</th>\n",
       "      <td>코로나, 방역, 정은경, 하루, 감염, 국방, 장관, 서욱, 총장, 집권, 아베, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-30</th>\n",
       "      <td>팔다리, 뱃살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>전공, 파업, 계속, 결정, 교수, 진도, 가세, 산다, 절체절명, 일주일, 민주당...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title\n",
       "date                                                         \n",
       "2020-01-01  공무원, 증, 밥값, 결제, 혁신, 준, 정부, 나은, 준비, 민주, 열망, 시대,...\n",
       "2020-01-02  김정은, 전략, 무기, 모라토리엄, 파기, 위협, 전문가, 공직, 배급, 스타트업,...\n",
       "2020-01-03  처지, 끝장, 생존, 게임, 구도, 오른, 총선, 전쟁, 패트, 몸싸움, 여야, 총...\n",
       "2020-01-04  트럼프, 중동, 화약고, 기업, 법, 시행, 땐, 툭하면, 공장, 이낙연, 황교안,...\n",
       "2020-01-06  법무부, 검사, 출신, 검찰, 국장, 기용, 검토, 이란, 시설, 타깃, 트럼프, ...\n",
       "...                                                       ...\n",
       "2020-08-27  의협, 파업, 강행, 정부, 면허, 취소, 압박, 기상청, 차량, 전복, 위험, 서...\n",
       "2020-08-28  단독, 교수, 진도, 파업, 동참, 서울대, 병원, 내과, 서나, 감염, 대통령, ...\n",
       "2020-08-29  코로나, 방역, 정은경, 하루, 감염, 국방, 장관, 서욱, 총장, 집권, 아베, ...\n",
       "2020-08-30                                            팔다리, 뱃살\n",
       "2020-08-31  전공, 파업, 계속, 결정, 교수, 진도, 가세, 산다, 절체절명, 일주일, 민주당...\n",
       "\n",
       "[209 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preprocessing('../../data/news_by_press(2020-01-01~2020-08-31)/동아일보')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해당 날짜를 입력하면 워드클라우드로 만들어져 그날 많이 나온 핵심 단어 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_news_title_wordcloud( date_to_search):\n",
    "    tmp_df = pd.read_csv('../../data/news_by_press(2020-01-01~2020-08-31)/')\n",
    "    \n",
    "    cloud = WordCloud(\n",
    "      font_path='../../fonts/NanumSquareRoundR.ttf'\n",
    "    , width=800\n",
    "    , height=600\n",
    "    , max_words=100\n",
    "    ).generate(''.join(tmp_df['title' ][tmp_df['date'] == date_to_search]))\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a36ecea51b99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdaily_news_title_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../data/news_by_press(2020-01-01~2020-08-31)/경향신문'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2020-01-01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-2cddc3b76ef0>\u001b[0m in \u001b[0;36mdaily_news_title_wordcloud\u001b[1;34m(file, date_to_search)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     ).generate(tmp_df['title' ][tmp_df['date'] == date_to_search])\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "daily_news_title_wordcloud('../../data/news_by_press(2020-01-01~2020-08-31)/경향신문','2020-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "npl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
