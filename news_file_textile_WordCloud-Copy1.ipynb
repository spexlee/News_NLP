{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜별 워드 클라우드로 가장 빈도수 높은 단어 도출 (title)\n",
    "- 이예빈\n",
    "- 참고: 불용어 사전 (https://www.ranks.nl/stopwords/korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not(os.path.isdir('./tokenized_news')):\n",
    "        os.makedirs(os.path.join('./tokenized_news'))\n",
    "                    \n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV_List로 만드는 함수\n",
    "def csv2list(filename):\n",
    "    lists = []\n",
    "    file = open(filename,'r',encoding='utf-8')\n",
    "    while True:\n",
    "        line = file.readline().rstrip('\\n')\n",
    "        if line:\n",
    "            lists.append(line)\n",
    "        else:\n",
    "            break\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = csv2list('../stop_words/stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 뉴스 제목에서 기호 제거 & 명사 추출 \n",
    "\n",
    "def textile_preprocessing(text, okt):\n",
    "    textile_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', ' ', text)\n",
    "    word_textile = okt.nouns(textile_text) \n",
    "    word_textile = [word for word in word_textile if not word in stop_words] # 불용어 제거\n",
    "    \n",
    "    return word_textile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전처리된 데이터프레임 by_day를 반환합니다. \n",
    "## file: csv파일이 들어있는 경로를 지정해주세요. (+ 파일까지 포함되도록!)\n",
    "\n",
    "def all_preprocessing(file):\n",
    "    df_file = pd.read_csv(file, encoding='utf-8')\n",
    "    \n",
    "#     textile = df_file['text']\n",
    "#     date_ = df_file['date']\n",
    "#     df = pd.DataFrame({'text':textile, 'date':date_})\n",
    "    \n",
    "    okt = Okt()\n",
    "    clean_text = []\n",
    "    for text in df_file['text']:\n",
    "        if type(text)==str:\n",
    "            clean_text.append(textile_preprocessing(text, okt))\n",
    "        else:\n",
    "            clean_text.append([])\n",
    "    df['text'] = clean_text\n",
    "    \n",
    "    # date 컬럼 -> datetime으로 설정 \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    by_day = df.groupby(df['date']).sum()\n",
    "\n",
    "    # 딕셔너리 풀기\n",
    "    news_textile = []\n",
    "    for i in tqdm(range(len(by_day['text']))):\n",
    "        news_textile.append(', '.join(by_day['text'][i]))\n",
    "\n",
    "    by_day['text'] = tqdm(news_textile)\n",
    "    \n",
    "    by_day.to_csv('./tokenized_news/tokenized_title_okt_nouns', encoding='utf-8')\n",
    "    \n",
    "    return by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-250aab3edf78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtmp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./1-8월 뉴스.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-39bfbeb36b19>\u001b[0m in \u001b[0;36mall_preprocessing\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mclean_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextile_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mclean_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-834a4a932aad>\u001b[0m in \u001b[0;36mtextile_preprocessing\u001b[1;34m(text, okt)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtextile_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtextile_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mword_textile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextile_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mword_textile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_textile\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 불용어 제거\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mnouns\u001b[1;34m(self, phrase)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"\"\"Noun extractor.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Noun'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     61\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp_df = all_preprocessing('./1-8월 뉴스.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.to_csv('./tokenized_news/tokenized_title_okt_nouns', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_news_title_wordcloud(file, date_to_search):\n",
    "    tmp_df = all_preprocessing(file)\n",
    "    \n",
    "    cloud = WordCloud(\n",
    "      font_path='../../fonts/NanumSquareRoundR.ttf'\n",
    "    , width=800\n",
    "    , height=600\n",
    "    , max_words=100\n",
    "    ).generate(tmp_df['text'][date_to_search])\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-95068905ff81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdaily_news_title_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./1-8월 뉴스.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2020-01-23'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-0944c7aa2f28>\u001b[0m in \u001b[0;36mdaily_news_title_wordcloud\u001b[1;34m(file, date_to_search)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdaily_news_title_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_to_search\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtmp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     cloud = WordCloud(\n\u001b[0;32m      5\u001b[0m       \u001b[0mfont_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../../fonts/NanumSquareRoundR.ttf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-06a403d67895>\u001b[0m in \u001b[0;36mall_preprocessing\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mclean_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextile_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mclean_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-834a4a932aad>\u001b[0m in \u001b[0;36mtextile_preprocessing\u001b[1;34m(text, okt)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtextile_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtextile_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mword_textile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextile_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mword_textile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_textile\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 불용어 제거\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mnouns\u001b[1;34m(self, phrase)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"\"\"Noun extractor.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Noun'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\npl\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     61\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "daily_news_title_wordcloud('./1-8월 뉴스.csv','2020-01-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>무너지는 일과 삶의 경계···노동이 녹아내린다</td>\n",
       "      <td>이 땅에서 ‘비정규직’이라는 표현이 광범위하게 쓰인 지 20여년. 정부가 신규 일자...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LPOD...</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일자리 아닌 일거리···'일정치 않음'을 살다 [녹아내리는 노동]</td>\n",
       "      <td>ㆍ①일자리보다 일거리\\n\\n노동의 미래를 모두 알 수는 없다. 다만 현실에서 일어나...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LPOD...</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이곳은…기계의 정확도 높이는 ‘인간부품’ 육성공장 아닐까 [녹아내리는 노동]</td>\n",
       "      <td>ㆍ①일자리보다 일거리\\n\\nㆍAI 학습데이터 가공 기업 ‘크라우드웍스’ 교육장 참관...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LPOD...</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지혜씨, 지훈씨를 부탁해! [인포그래픽]</td>\n",
       "      <td>새로 태어나는 아이들은 줄어들고 어르신들은 계속 나이를 먹어 갑니다. 2020년 새...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LPOD...</td>\n",
       "      <td>경향신문</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20대 리포트] “20대, 함부로 판단말라… 내 길 내가 간다”</td>\n",
       "      <td>새천년의 시작과 함께 세상에 나온 2000년대생들이 어느덧 사회 변화를 이끌 20대...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LPOD...</td>\n",
       "      <td>국민일보</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   무너지는 일과 삶의 경계···노동이 녹아내린다   \n",
       "1        일자리 아닌 일거리···'일정치 않음'을 살다 [녹아내리는 노동]   \n",
       "2  이곳은…기계의 정확도 높이는 ‘인간부품’ 육성공장 아닐까 [녹아내리는 노동]   \n",
       "3                      지혜씨, 지훈씨를 부탁해! [인포그래픽]   \n",
       "4        [20대 리포트] “20대, 함부로 판단말라… 내 길 내가 간다”   \n",
       "\n",
       "                                                text  \\\n",
       "0  이 땅에서 ‘비정규직’이라는 표현이 광범위하게 쓰인 지 20여년. 정부가 신규 일자...   \n",
       "1  ㆍ①일자리보다 일거리\\n\\n노동의 미래를 모두 알 수는 없다. 다만 현실에서 일어나...   \n",
       "2  ㆍ①일자리보다 일거리\\n\\nㆍAI 학습데이터 가공 기업 ‘크라우드웍스’ 교육장 참관...   \n",
       "3  새로 태어나는 아이들은 줄어들고 어르신들은 계속 나이를 먹어 갑니다. 2020년 새...   \n",
       "4  새천년의 시작과 함께 세상에 나온 2000년대생들이 어느덧 사회 변화를 이끌 20대...   \n",
       "\n",
       "                                                 url media        date  \n",
       "0  https://news.naver.com/main/read.nhn?mode=LPOD...  경향신문  2020-01-01  \n",
       "1  https://news.naver.com/main/read.nhn?mode=LPOD...  경향신문  2020-01-01  \n",
       "2  https://news.naver.com/main/read.nhn?mode=LPOD...  경향신문  2020-01-01  \n",
       "3  https://news.naver.com/main/read.nhn?mode=LPOD...  경향신문  2020-01-01  \n",
       "4  https://news.naver.com/main/read.nhn?mode=LPOD...  국민일보  2020-01-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = pd.read_csv('./1-8월 뉴스.csv')\n",
    "aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "npl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
